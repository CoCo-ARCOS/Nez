{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Nez","text":"<p>Nez is a design-driven skeleton model that enables the construction of AI-based and analytic systems that run seamlessly across the computing continuum (from edge to cloud to HPC).</p>"},{"location":"#services-and-containers","title":"Services and Containers","text":"<p>The following services are defined in the <code>docker-compose.yml</code> file:</p>"},{"location":"#core-services","title":"Core Services","text":"<ul> <li><code>valuechain</code>: Graphical interface for building AI-based systems  </li> <li><code>value-chain-api</code>: API for system construction  </li> <li><code>deployer</code>: Deployment service with validation mechanisms  </li> <li><code>value-chain-api-db</code>: Database for system construction  </li> <li><code>container-manager</code>: Container manager  </li> </ul>"},{"location":"#data-management","title":"Data Management","text":"<ul> <li><code>apigateway</code>: API Gateway  </li> <li><code>auth</code>: User authentication  </li> <li><code>db_auth</code>: User database  </li> <li><code>frontend</code>: Catalog management interface  </li> <li><code>db_pub_sub</code>: Pub/Sub service  </li> <li><code>pub_sub</code>: Pub/Sub database  </li> <li><code>db_metadata</code>: Metadata service  </li> <li><code>metadata</code>: Metadata database  </li> </ul>"},{"location":"#storage-load-balancing","title":"Storage &amp; Load Balancing","text":"<ul> <li><code>storage1, storage2, storage3, storage4, storage5</code>: Storage services  </li> <li><code>balancing</code>: Load balancing service  </li> </ul>"},{"location":"#data-preparation-recovery","title":"Data Preparation &amp; Recovery","text":"<ul> <li><code>sincronizador</code>  data uploading client</li> <li><code>PreparationSchemes</code>  NRFs manager</li> </ul>"},{"location":"#software-prerequisites","title":"Software Prerequisites","text":"<p>Nez services run on container technology to simplify deployment. Install the following dependencies:</p> <ul> <li>Docker v20.10.23 </li> <li>Docker Compose v2.15.1 </li> <li>Java 17 or higher </li> </ul>"},{"location":"example_deployment/","title":"Deployment example","text":"<p>To simplify the installation and deployment of Nez services, this project includes an <code>install.sh</code> script that automates the setup on a single machine. On a Linux terminal, run:</p> <pre><code>cd services\nbash install.sh\n</code></pre> <p>You will be asked to confirm or manually enter the IP address of the machine where the services will be deployed.</p>"},{"location":"example_deployment/#key-steps-in-the-setup","title":"Key Steps in the Setup","text":""},{"location":"example_deployment/#1-configure-container-volumes","title":"1. Configure container volumes","text":"<p>This ensures file sharing between services and with the host machine:</p> <pre><code>gateway=\"      URL: \\\"http://${my_ip}:20505\\\"\"\nhostpath=\"      HOST_PATH: $PWD/deployer/app/\"\nvolumehost=\"      - \\\"$PWD/deployer/app/:$PWD/deployer/app/\\\"\"\n\nsed -i \"225s#.*#$gateway#\" ./docker-compose.yml\nsed -i \"64s#.*#$hostpath#\" ./docker-compose.yml\nsed -i \"61s#.*#$volumehost#\" ./docker-compose.yml\n</code></pre> <p>This step sets static paths to ensure correct operation of Nez services and containers.</p>"},{"location":"example_deployment/#2-run-configuresh","title":"2. Run <code>configure.sh</code>","text":"<p>This script creates test data and completes the system setup. Ensure the IP address matches the one used earlier:</p> <pre><code>cd CodigoFuente\nbash configure.sh\n</code></pre>"},{"location":"example_deployment/#3-create-a-test-organization-and-user","title":"3. Create a test organization and user","text":"<p>Using Painal\u2019s authentication service:</p> <pre><code># Create organization\ncurl --header \"Content-Type: application/json\" --request POST --data '{ \"acronym\": \"TEST\", \"fullname\": \"TESTORG\", \"fathers_token\": \"/\" }' http://${my_ip}:20500/auth/v1/hierarchy/create \n\n# Create test user\ncurl --header \"Content-Type: application/json\" --request POST --data '{\"username\":\"testuser\",\"password\":\"TestUser123.\", \"email\":\"test@test.com\", \"tokenorg\":\"'$TOKEN_ORG'\"}' http://${my_ip}:20500/auth/v1/users/create\n</code></pre>"},{"location":"example_deployment/#4-configure-storage-nodes","title":"4. Configure storage nodes","text":"<pre><code>for i in 06 07 08 09 10\ndo\n    curl -X POST -F \"capacity=40000000000\" -F \"memory=2000000000\" -F \"url=$my_ip:200$i/\" http://$my_ip:20505/configNodesPost.php\n    echo \" \"\ndone\n</code></pre>"},{"location":"example_deployment/#5-create-a-test-catalog-and-upload-data","title":"5. Create a test catalog and upload data","text":"<pre><code># Create catalog\ncurl --header \"Content-Type: application/json\" --request POST --data '{ \"catalogname\": \"TESTCATALOG\", \"dispersemode\": \"false\", \"encryption\":\"true\", \"fathers_token\":\"/\"}' http://${my_ip}:20500/pub_sub/v1/catalogs/create?access_token=$access_token\n\n# Upload sample data\njava -jar Upload.jar $tokenuser $apikey $tokencatalog SINGLE bob 2 $PWD/../datosprueba TESTORG true $access_token true false 4\n</code></pre>"},{"location":"example_deployment/#6-load-and-register-skeletons-in-nez","title":"6. Load and register skeletons in Nez","text":"<pre><code># Load container images\ndocker load -i microservicios/cleaner.tar  \ndocker load -i microservicios/deteccion.tar  \ndocker load -i microservicios/dicomtorgb.tar  \ndocker load -i microservicios/tc.tar\n\n# Register skeletons in Nez\ncurl --header \"Content-Type: application/json\" --request POST --data '{\"name\":\"Anonimizacion\", \"command\":\"python3 /code/process_dir.py --input @I --outfolder \\\"@D\\\" --save dicom\", \"image\":\"ddomizzi/cleaner:header\", \"description\":\"Anonymization of DICOM images\"}' \"http://${my_ip}:20510/api/v1/buildingblocks?access_token=$tokenuser\"\n\ncurl --header \"Content-Type: application/json\" --request POST --data '{\"name\":\"ToRGB\", \"command\":\"python3 /code/dicom2rgb.py @I @D/@L\", \"image\":\"ddomizzi/dicomtorgb:v1\", \"description\":\"Convert DICOM images to RGB\"}' \"http://${my_ip}:20510/api/v1/buildingblocks?access_token=$tokenuser\"\n\ncurl --header \"Content-Type: application/json\" --request POST --data '{\"name\":\"DetectorPulmon\", \"command\":\"python3 /code/detectorPulmones.py @I @D/@L\", \"image\":\"ddomizzi/deteccion:pulmon\", \"description\":\"Lung anomaly detection in CT scans\"}' \"http://${my_ip}:20510/api/v1/buildingblocks?access_token=$tokenuser\"\n</code></pre>"},{"location":"example_deployment/#registered-skeletons","title":"Registered skeletons","text":"<ul> <li>Anonymization: Removes personal data from DICOM metadata.  </li> <li>ToRGB: Converts DICOM images into PNG format.  </li> <li>Lung Detector: Identifies tumors in lung CT scans (PNG).  </li> </ul>"},{"location":"example_deployment/#example-designing-and-executing-an-ai-based-service-for-medical-image-management","title":"Example: Designing and Executing an AI-Based Service for Medical Image Management","text":"<ol> <li> <p>To design a service, go to http://localhost:22101/ (replace <code>localhost</code> with the IP address of the machine where the services were deployed) and log in with the following credentials:</p> </li> <li> <p>Email: test@test.com  </p> </li> <li>Password: TestUser123.  </li> </ol> <p></p> <ol> <li>In the side menu, navigate to <code>Systems &gt; Create a system</code>. This screen will show the skeletons that were previously configured and registered. Click the <code>Add</code> button.</li> </ol> <p></p> <ol> <li>In Step 2, select the non-functional requirements you want to add to your data.  </li> <li>In Step 3, choose the CDN data catalog to be processed. </li> <li> <p>In Step 4, define the execution order of your skeletons. </p> </li> <li> <p>Click <code>Save</code> and provide a name for your solution. You will be redirected to the deployment screen, where you can select the deployment method:  </p> </li> <li> <p>Compose: Deploy the solution on a single machine. </p> <p> </p> </li> </ol> <p>If you receive an error message during deployment, click the <code>Deploy</code> button again. You can verify that the containers were deployed by running the following command in a terminal:  </p> <p><code>bash    docker ps</code></p> <ol> <li> <p>Once your services is deployed. Click on <code>Execute</code> to start the processing of data with your service.</p> <p></p> </li> <li> <p>This will start the processing of data. When completed, you can see the resultant files by clicking on <code>See results</code> button. This will redirect you to the Nez file manager. </p> <p></p> </li> <li> <p>You can physically see your results by opening a file explorer and navigating to: <code>services/deployer/app/results</code>. Here you can find the workspace of the services deployed.</p> <p></p> </li> </ol>"},{"location":"concepts/","title":"Nez concepts","text":"<p>Nez is a design-driven skeleton model for building AI-based and analytic systems in the computing continuum. It integrates AI applications with security, fault tolerance, and data management into efficient and secure workflows.</p>"},{"location":"concepts/#what-is-nez","title":"\ud83d\udcd6 What is Nez?","text":"<ul> <li>A framework that transforms high-level designs into deployable continuum systems.  </li> <li>Supports AI/ML applications, data orchestration, and non-functional requirements (NFRs).  </li> <li>Deployed in real-world domains such as healthcare and earth observation.  </li> </ul>"},{"location":"concepts/#quick-links","title":"\ud83d\udcda Quick Links","text":"<ul> <li>Overview </li> <li>Architecture </li> <li>Features </li> </ul>"},{"location":"concepts/architecture/","title":"Architecture","text":"<p>Nez follows a skeleton-based construction model: - Skeletons: Encapsulate applications with dependencies. - Self-similar design: Enables modularity, portability, and reuse.  </p>"},{"location":"concepts/architecture/#core-components","title":"\ud83c\udfd7\ufe0f Core Components","text":"<ol> <li>Design Layer</li> <li>Web-based Nez GUI.  </li> <li>Graphical system design using blocks and skeletons.  </li> <li> <p>Generates JSON system configuration.</p> </li> <li> <p>Deployment Layer</p> </li> <li>Code generator: Produces YAML, JSON, Dockerfiles.  </li> <li> <p>Deployment orchestrator: Instantiates containers across infrastructures.  </p> </li> <li> <p>Execution Layer</p> </li> <li>Execution manager: Ensures order and orchestration.  </li> <li>Data orchestrator: Moves data using a CDN with pub/sub model.  </li> <li> <p>Supports intra- and inter-institutional deployments.  </p> </li> <li> <p>Monitoring Manager</p> </li> <li>Detects service failures.  </li> <li>Relaunches or reassigns services to alternative resources.  </li> </ol>"},{"location":"concepts/architecture/#security-mechanisms","title":"\ud83d\udd10 Security Mechanisms","text":"<ul> <li>Confidentiality: AES-256 + CP-ABE encryption.  </li> <li>Integrity: SHA-256 checks.  </li> <li>Availability: Replication + Information Dispersal Algorithm (IDA).  </li> </ul>"},{"location":"concepts/features/","title":"Features","text":""},{"location":"concepts/features/#key-features","title":"\ud83c\udf1f Key Features","text":"<ul> <li>Transparency: Automatic integration of NFRs (confidentiality, reliability, access control).  </li> <li>Efficiency: Up to 28% faster than Nextflow in experiments.  </li> <li>Resilience: Adds redundancy and encryption to ensure secure dataflows.  </li> <li>Continuum-ready: Works across edge, fog, cloud, and HPC infrastructures.  </li> </ul>"},{"location":"concepts/features/#technical-highlights","title":"\ud83d\udd27 Technical Highlights","text":"<ul> <li>Parallel patterns: Manager/worker, divide-and-conquer.  </li> <li>Load balancing: \"Two choices\" algorithm for dynamic distribution.  </li> <li>Containers: Docker and Singularity for portability.  </li> <li>Automation: From design \u2192 code generation \u2192 deployment \u2192 execution.  </li> </ul>"},{"location":"concepts/overview/","title":"Overview","text":"<p>Organizations increasingly rely on AI and ML to process data, automate tasks, and support decision-making. The computing continuum (edge\u2013fog\u2013cloud) enables these applications to run closer to data sources, reducing latency and improving efficiency.  </p>"},{"location":"concepts/overview/#the-challenge","title":"\u274c The Challenge","text":"<ul> <li>Manual deployment and integration are complex.  </li> <li>Non-functional requirements (NFRs) such as security, fault tolerance, and reliability are difficult to enforce.  </li> <li>Heterogeneous infrastructures increase complexity.</li> </ul>"},{"location":"concepts/overview/#the-solution","title":"\u2705 The Solution","text":"<p>Nez introduces a skeleton model: - Automatically couples AI applications with NFR components. - Provides a design-driven interface for system creation. - Dynamically deploys across multiple infrastructures.  </p> <p>Nez has been validated in medical imaging and satellite imagery case studies, outperforming workflow engines such as Nextflow, Parsl, and Makeflow.  </p>"}]}